# Introduction: Recent studies

What is rock? Is it a genre? a style? a conglomeration of genres and subgenres, styles and substyles? Is it a single entity at all? Or is it such a diffuse and subjective category that study of its underlying structure is doomed to failure?

Recent empirical studies of rock (or pop/rock) harmony have touched upon these problematic questions. Referring to their study of a sample of songs from *Rolling Stone* magazine's "500 Greatest Songs of All Times," DeClercq and Temperley (2011) write, "'rock' proves to be a problematic term. . . . It might be argued that what our corpus represents is not a single unified style, but perhaps several styles, each of which may have a more consistent harmonic logic than is reflected by the data we have presented above (this brings to mind Everett's six 'tonal systems')" (50–51). Similarly, John Ashley Burgoyne concludes his (2011) dissertation analyzing a sample of songs from the *Billboard* Hot 100 reiterating the point that "most proportions derived from data are 'over-dispersed'," with the harmonic structure of the McGill Billboard corpus being no exception (188). By "over-dispersed" Burgoyne means that the harmonic structures of individual songs are noticeably different from the average structures of the corpus. This song-by-song uniqueness is not surprising, given the creativity of songwriters, but it problematizes the use of corpus-wide averages as representative measures of the corpus as a whole, let alone the greater population of which the corpus is a sample.

The problematic nature of the terms "rock," "pop," and "pop/rock" likely emerge for a number of reasons. First, these terms are applied to very large repertoires of music by musicians and listeners alike. Hendrik Schreiber (2015) investigated user-generated genre tags in online music services and found that "pop/rock" was applied to as many as 60% of recent popular songs; when separated, "pop" was applied to roughly 7%, "rock" to 39%, and the rock-related terms "metal" and "punk" were applied to another 7% of songs. "Rock" and "pop/rock" seem to be very broad categories, and perhaps ill-defined, or at least diversely defined, among listeners.

Second, there is a disconnect between genre and style that is not always accounted for in empirical musical studies. Allan F. Moore (2001) addresses this distinction in detail. For our purposes, it is most significant to note the *social* component to genre and the *structural* focus of style. When computational theorists study the structure of songs, we cannot assume a shared underlying structural grammar simply because listeners have categorized songs according to the same genre. For example, in an article introducing the Million Song Dataset (2011), Thierry Bertin-Mahieux et al. provide sample genre tags for Britney Spears and Bon Jovi, from The Echo Nest and from Musicbrainz. Bon Jovi is tagged as "Adult Contemporary," "Arena Rock," and "80s" (The Echo Nest); "Hard Rock," "Glam Metal," and "American" (Musicbrainz). Britney Spears is tagged as "Teen Pop," "Soft Rock," and "Female" (The Echo Nest); "Pop," "American," and "Dance" (Musicbrainz). Even without an empirical comparison of the structural properties of these two artists' music, we can see likely social components to these tags that would be difficult to delineate structurally. For example, what makes Britney Spears's music "female," especially considering the fact that a number of her songs were written by men? And why is Bon Jovi's music "hard" rock while Britney Spears's music is "soft" rock? Is there an objective structural feature set that delineates hard from soft in this context, or is there a social, and gendered, component to these genre tags, as is likely with the "female" tag applied to Britney Spears? Further, consider the tags likely contributed by those whose musical preferences differ. We suggest that a fan of country or gospel is more likely to use the word "metal" when describing Bon Jovi than a fan of Judas Priest and Black Sabbath is. At the very least, we cannot rule out the possible subjectivity of these terms without further empirical study.

Whatever the reasons, it is clear that it would be beneficial to study further the possibility of multiple stylistic practices being contained within the broad genre labels of "pop" and "rock," especially when considering these terms over the course of a time period as broad as the *Rolling Stone* and McGill Billboard corpora represent.

However, there is a chicken-and-egg problem here. In order to precisely define "rock" or one of its potential sub-styles empirically, we need to know what songs do and don't belong within the category of "rock." However, as Burgoyne and DeClercq/Temperley show, we *don't* know which songs do and do not belong inside that category. For that we need data from the songs. Which requires knowing which songs. Which requires data from the songs. And so on, ad infinitum.

But there is an empirical tool that can assist us with this problem. Both Burgoyne and DeClercq and Temperley mention the machine-learning technique of *cluster analysis* as a possible tool for discovering the emergent harmonic styles represented in these corpora. K-Means cluster analysis is an unsupervised machine-learning algorithm that takes a collection of data points, measures their distance from each other in some predefined space, and attempts to find the tightest clusters of data points: those points (in this case, songs) that are the most near (like) each other, but the most distant from (unlike) the points in other clusters. This tightness-of-clusters property is a sum-of-squares statistical measurement called *inertia*. This gives us a tool to crack our chicken-and-egg problem: collect a large dataset of popular songs, define each song as a point in harmonic-practice space, perform a cluster analysis of the corpus in that space, and uncover the clustering solution with the best inertia and the greatest musicological significance. Then we can analyze the songs in each cluster to find what specific harmonic practices are contained within the larger corpus, whose properties have been averaged over by the corpus-wide analysis.

We (the instructor and students in a vertically integrated, interdisciplinary course on computational music analysis at the University of Colorado–Boulder) performed just such an analysis on the songs in the McGill Billboard Dataset (Version 2.0). As the following results demonstrate, there does seem to be multiple distinct harmonic (sub-)grammars present in the McGill Billboard corpus, and these (sub-)grammars bear significant similarity to the "tonal systems" proposed by Walter Everett (2004) as well as to a number of proposed pop/rock harmonic schemata (many of which are listed on [*Open Music Theory*](http://openmusictheory.com/popRockHarmony)).

# The dataset

To conduct this study, we used the McGill Billboard dataset (version 2.0, available from http://ddmal.music.mcgill.ca/billboard and described in detail in Burgoyne 2011). This dataset, which we will refer to as BB, contains detailed harmonic information for 730 songs taken from the Billboard Hot 100 Singles charts from 1958 to 1991 (***double-check this***). Because it is taken from the Hot 100, it is a sample of songs that were popular at some point in their history, but does not claim to represent a single genre. In fact, the Hot 100 list routinely comprises a variety of genres, and as noted above, presents a statistically "over-dispersed" harmonic practice, with most songs exhibiting significantly different harmonic structures than the corpus average. Thus it not only provides a ready-made collection of harmonically tagged musical data for computational analysis, but it also presents an ideal environment for testing the hypothesis that there are multiple structural grammars in this single corpus.

However, BB is not entirely ready-made for such an analysis. The dataset contains detailed harmonic tagging, but as absolute chord designations (i.e., lead-sheet symbols) rather than relative to a tonic (i.e., Roman numerals). Thus we created a parser (a Python script) that would use the absolute chord data and the tonic pitch provided in BB's metadata for each song, and produce a list of chords as functional entities, represented by Roman numerals.


We also decided to use those Roman numerals to represent *only the scale-degree of the chord's root*, not chord quality or the presence of chord extensions (sevenths, ninths, elevenths, thirteenths), the absence of chord tones (power chords), or the presence of suspended tones (typically seconds or fourths). This was partly because of the emphasis on root progressions in many theories of tonal harmony, but mostly because of statistical concerns. When dealing with bigrams (chord-to-chord progressions) and twelve possible chord roots, there are 144 (12x12) possible bigrams, and thus 144 dimensions to a potential cluster analysis. This is already a very high-dimensional study, especially given the size of the dataset, and most of these dimensions will be empty for a given song (that is, zero occurrences of that particular bigram). Each additional chord parameter adds twelve new possible starting and ending chords, rapidly increasing the dimensionality of the harmonic space. And since a very small set of chord qualities and configurations account for such a high percentage of the chords in the corpus (***specifics!!!***), the potential statistical payoff of accounting for chord varieties other than chord root was very low and came at both a computational and a statistical cost.

Once we had the harmonic data reduced and translated to chord roots relative to a tonic, we analyzed each song for its chord-progression content. For each chord-to-chord transition (bigram), we calculated the probability of the arrival chord given the starting chord. Given a IV chord, what is the probability in a given song that the following chord is I? flat-II? II? ... VII? For each song, this analysis produced 144 probability values: I–I, I–bII, I–II, ... VII–VII. The twelve probabilities that start with the same chord (e.g., I–I, I–bII, ... I-VII) sum to 1 (or to 0, if the starting chord is not present in the song). This series of 144 values served as the basis both of our corpus-wide average calculations, and the cluster analysis.

Following is a sample bigram analysis for a single song, represented as a 12x12 table rather than a vector for easier reading. Probabilities represent the probability of the target chord (top row) given the preceding chord (left column). Each row sums to 1 or 0.

***sample song table***

And following is the song-by-song average for the entire corpus. (All average probability tables in this article have been normalized so that each row sums to 1. Because some songs will have zeroes for each value in a row, not all averages will sum to 1 without this normalization, leading to difficulty reading and interpreting the tables. Normalized tables make both within-table and cross-table comparisons easier.)


***whole-corpus probability table***

# Analytical methods

The goal of this study is to use the machine learning technique of cluster analysis in combination with ad hoc human analysis to test the hypothesis that the McGill Billboard dataset contains exemplars of multiple harmonic grammars, rather than a single "average" harmonic grammar (see above figure). In statistical terms, we hypothesize that the BB corpus is not a sample of a single population of pop songs, but rather a mixture of samples from a variety of musical styles. We also hope to produce empirical data that problematizes the equating of style and genre, something that is common in the machine learning community when addressing musical data.

To test this hypothesis, we subjected the 144-dimensional bigram (chord-to-chord transition) analysis described above to a K-means cluster analysis.&nbsp;K-Means cluster analysis is an unsupervised machine-learning algorithm that takes a collection of data points, measures the Euclidean distance from each other in some predefined space, and attempts to find the tightest clusters of data points: those points (in this case, songs) that are the most near (like) each other, but the most distant from (unlike) the points in other clusters.&nbsp;This tightness-of-clusters property is a sum-of-squares statistical measurement called *inertia*.&nbsp;This gives us a tool to crack the chicken-and-egg problem described in the introduction: collect a large dataset of popular songs, define each song as a point in (144-dimension) harmonic-practice space, perform a cluster analysis of the corpus in that space, and uncover the clustering solution with the best inertia and the greatest musicological significance. Then we can analyze the songs in each cluster to find what specific harmonic practices are contained within the larger corpus, whose properties have been averaged over by the corpus-wide analysis.

K-means cluster analysis, like all unsupervised machine-learning algorithms, has the advantage of the resulting clusters -- in this case, the harmonic grammars present in the corpus -- being emergent. However, the *number*&nbsp;of clusters must be predetermined by the analyst, and can be anything from one cluster (a trivial case) to 730 clusters (another trivial case, with each cluster containing a single song). How do we choose the appropriate number of clusters? (We will refer to the number of clusters as the *cardinality*&nbsp;of the clustering solution.)

For a dataset the size of BB, it is not difficult to run the clustering algorithm multiple times with different cardinalities, even on a personal computer. (We used an eight-core Mac Pro for this study, and it was more than up to the task, running multiple clustering epochs in a matter of minutes.) Further, each clustering solution produces a single *inertia*&nbsp;value that represents the tightness of the clusters, making it easy to compare the results of even a large number of cardinalities to find the tightest fit.&nbsp;

However, the more clusters contained in a solution, the more unwieldy the musical analysis. Harmonic "grammars" proliferate, and categories become too small to represent a meaningful generalization of a musical practice. Further, our study would also hit a *human&nbsp;*bottleneck if we were to analyze the 144 probability values in all 266,815 clusters produced by running the algorithm on each cardinality from 1 to 730. In order to find an optimal clustering solution, we need to form a specific hypothesis to test, limiting the algorithmic output to something that is both analyzable by humans and that has the potential to represent something that is musically meaningful.

With that in mind, we formed two specific hypotheses based on existing research on style and genre in popular music, and sought clustering solutions in and around those hypothetical scenarios.

The first hypothesis comes from Walt Everett's (2004) six "tonal systems," two of which were divided into two subsystems, rendering a potential of 6–8 harmonic grammars in music Everett categorized as "rock" (note the genre–style relationship). It is important to note that in Everett's article, he purposefully went *outside*&nbsp;the popularity charts to find songs that he believed were important or influential in rock history. This led to at least one tonal system that likely would not exist in a study that, like ours, is based entirely on the Billboard charts.&nbsp;Based on Everett's study, then, we hypothesized that there were between filve and eight harmonic (sub-)grammars in the BB corpus, and thus that a clustering solution with cardinality 5, 6, 7, or 8 would be optimal.

The second hypothesis comes from Schreiber (2015), who settled on a list of fifteen *genre*&nbsp;tags for popular music, based on user-generated tags for songs affiliated with another popular music dataset. We decided to test the hypothesis that the relationship between user-tagged genre and structural style would be strong and, therefore, there would be fifteen harmonic (sub-)grammars in the BB corpus, leading to an optimal clustering solution with cardinality 15. (Note that because we find the genre–style conflation to be problematic, and because harmonic grammar is not the only distinguishing marker of a musical style, we predicted that cardinality 15 would *not*&nbsp;likely produce the optimal clustering solution.)

To test these hypotheses, as well as other options near to them, we constructed a set of scripts (using Python and the machine-learning toolkit SciKit-Learn) that would run the clustering algorithm for cardinalities 1–15. This would give us a base-line inertia value for a corpus-wide average (cardinality 1), as well as all of the cardinalities suggested by the Everett-based hypothesis and the Schreiber-based hypothesis, and other values between those. (We were also open to the possibility of testing a higher cardinality if the results of these tests suggested it would be useful, but as will be discussed in what follows, that was not the case.)

*All code, as well as the translated version of the BB corpus that we used, can be found in our GitHub repository for this project (github.com/corpusmusic/bb-cluster). We invite interested readers to reproduce our results, as well as to submit corrections and/or enhancements to the repository.*


# The results

# The significance
